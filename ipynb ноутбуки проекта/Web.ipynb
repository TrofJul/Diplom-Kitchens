{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXznhR58b86G"
      },
      "source": [
        "%%capture\n",
        "!pip install --upgrade streamlit\n",
        "!pip install pyngrok\n",
        "!pip install wget\n",
        "!pip install ColorDetect\n",
        "\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "!pip install tf_slim\n",
        "!pip install tf-models-official\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "!cd models/research; protoc object_detection/protos/*.proto --python_out=.\n",
        "!cd models/research; export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim; python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Ze1I1-dbKF",
        "outputId": "0a409231-8f11-4b37-d01a-4f437c95ea0c"
      },
      "source": [
        "%%writefile kitchens.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from IPython.utils import io\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import requests\n",
        "\n",
        "from colordetect import ColorDetect\n",
        "import webcolors\n",
        "\n",
        "import sys, os\n",
        "sys.path.append('models/research')\n",
        "sys.path.append('models/research/object_detection')\n",
        "\n",
        "from time import process_time\n",
        "import six.moves.urllib as urllib\n",
        "from collections import Counter\n",
        "import tarfile\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "\n",
        "''''''\n",
        "#Вспомогательные функции для скачивания файлов\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "download_file_from_google_drive('1omZW_rWygbLvvQ399PnmD-LdZHOxpSZ_', 'weigths.pth')\n",
        "#download_file_from_google_drive('1ipDvv0tPxu63GrmVM0yQ5E7ispL7HEi_', 'label_encoder.pkl')\n",
        "download_file_from_google_drive('1ipDvv0tPxu63GrmVM0yQ5E7ispL7HEi_', 'faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28.tar.gz')\n",
        "\n",
        "\n",
        "''''''\n",
        "#Детекция объектов\n",
        "\n",
        "model_path = 'http://download.tensorflow.org/models/object_detection/'\n",
        "model_name = 'faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28'\n",
        "\n",
        "mod = wget.download(model_path + model_name + '.tar.gz')\n",
        "tar = tarfile.open(mod, 'r:gz')\n",
        "model_file_name =  model_name + '/frozen_inference_graph.pb'\n",
        "tar.extract(model_file_name)\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(model_file_name, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "category_index = {\n",
        "    62: {'id': 62, 'name': 'chair'},\n",
        "    63: {'id': 63, 'name': 'couch'},\n",
        "    67: {'id': 67, 'name': 'dining table'},\n",
        "    72: {'id': 72, 'name': 'tv'},\n",
        "    78: {'id': 78, 'name': 'microwave'},\n",
        "    79: {'id': 79, 'name': 'oven'},\n",
        "    80: {'id': 80, 'name': 'toaster'},\n",
        "    81: {'id': 81, 'name': 'sink'},\n",
        "    82: {'id': 82, 'name': 'refrigerator'}\n",
        "}\n",
        "\n",
        "translation = {\n",
        "    'chair' : 'стул',\n",
        "    'couch':  'диван',\n",
        "    'dining table': 'кухонный стол',\n",
        "    'tv': 'телевизор',\n",
        "    'microwave': 'микроволновая печь',\n",
        "    'oven': 'духовка',\n",
        "    'toaster': 'тостер',\n",
        "    'sink': 'раковина',\n",
        "    'refrigerator': 'холодильник'\n",
        "}\n",
        "\n",
        "\n",
        "def load_image(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      \n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Запуск поиска объектов\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # Преобразование выходных данных из массивов float32 в нужный формат\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "  return output_dict\n",
        "\n",
        "def filter_output(output_dict):\n",
        "    my_categories = category_index.keys()\n",
        "    for i in range(len(output_dict['detection_classes'])):\n",
        "        if not (output_dict['detection_classes'][i] in my_categories):\n",
        "            output_dict['detection_classes'][i] = 1\n",
        "            output_dict['detection_scores'][i] = 0\n",
        "            output_dict['detection_boxes'][i] = [0., 0., 0., 0.]\n",
        "\n",
        "def count_objects(output_dict):\n",
        "    init_dict = {62: 0, 63: 0, 67: 0, 72: 0, 78: 0, 79: 0, 81: 0, 82: 0}\n",
        "    filtered_output = []\n",
        "\n",
        "    for i in range(len(output_dict['detection_classes'])):\n",
        "      if output_dict['detection_classes'][i] in category_index.keys() and output_dict['detection_scores'][i] > 0.5:\n",
        "        filtered_output.append(output_dict['detection_classes'][i])\n",
        "    \n",
        "    counted_output = dict( list(init_dict.items()) + list(dict(Counter(filtered_output)).items()))\n",
        "    result = counted_output.copy()\n",
        "    for i in counted_output:\n",
        "      result[category_index[i]['name']] = result.pop(i)\n",
        "    return result\n",
        "\n",
        "def classify(counted_objects):\n",
        "    if counted_objects['oven'] > 0 or counted_objects['sink'] > 0 or counted_objects['refrigerator'] > 0:\n",
        "      placeholder_text.subheader('На фотографии действительно изображена *кухня*')\n",
        "      st.write('\\n')\n",
        "      isKitchen = True\n",
        "    else:\n",
        "      placeholder_text.subheader('Кажется на этой фотографии изображена *не кухня*, загрузите другое фото')\n",
        "      st.write('\\n')\n",
        "      isKitchen = False\n",
        "    return isKitchen\n",
        "\n",
        "def detect(jpg):\n",
        "    kitchen = load_image(jpg)\n",
        "\n",
        "    start_time = process_time() \n",
        "    output_dict = run_inference_for_single_image(kitchen, detection_graph)\n",
        "\n",
        "    filter_output(output_dict)\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          kitchen,\n",
        "          output_dict['detection_boxes'],\n",
        "          output_dict['detection_classes'],\n",
        "          output_dict['detection_scores'],\n",
        "          category_index,\n",
        "          instance_masks=output_dict.get('detection_masks'),\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=6,\n",
        "          min_score_thresh=.6)\n",
        "    plt.figure(figsize=(20, 12))\n",
        "    plt.grid(False)\n",
        "    placeholder_im.image(kitchen)\n",
        "    placeholder_time.write('detection time: ' + str(round(process_time()  - start_time)) + ' seconds')\n",
        "\n",
        "    counted_objects = count_objects(output_dict)\n",
        "    counted_objects_tr = {}\n",
        "\n",
        "    for obj in counted_objects.keys():\n",
        "      counted_objects_tr[translation[obj]] = counted_objects[obj]\n",
        "\n",
        "    isKitchen = classify(counted_objects)\n",
        "    if isKitchen:\n",
        "      with right_column:\n",
        "        for obj in counted_objects_tr.items():\n",
        "          st.write(f'**{obj[0]}**' + ': ' + str(obj[1]))\n",
        "    return isKitchen\n",
        "''''''\n",
        "#Классификация кухни по конфигурации\n",
        "\n",
        "# разные режимы датасета \n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# все изображения будут масштабированы к размеру 224x224 px\n",
        "RESCALE_SIZE = 224\n",
        "\n",
        "class KitchenDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Датасет с картинками, который паралельно подгружает их из папок\n",
        "    производит скалирование и превращение в торчевые тензоры\n",
        "    \"\"\"\n",
        "    def __init__(self, files, mode):\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        # режим работы\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "\n",
        "        self.len_ = len(self.files)\n",
        "     \n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            self.labels = [path.parent.name for path in self.files]\n",
        "            self.label_encoder.fit(self.labels)\n",
        "\n",
        "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "                  pickle.dump(self.label_encoder, le_dump_file)\n",
        "                      \n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "      \n",
        "    def load_sample(self, file):\n",
        "        image = np.asarray(file)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.convert('RGB')\n",
        "        image.load()\n",
        "        return image\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "        x = self.load_sample(self.files[index])\n",
        "        x = self._prepare_sample(x)\n",
        "        x = np.array(x / 255, dtype='float32')\n",
        "        x = transform(x)\n",
        "        if self.mode == 'test':\n",
        "            return x\n",
        "        else:\n",
        "            label = self.labels[index]\n",
        "            label_id = self.label_encoder.transform([label])\n",
        "            y = label_id.item()\n",
        "            return x, y\n",
        "        \n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "        return np.array(image)\n",
        "\n",
        "def predict_one_sample(model, inputs, device='cpu'):\n",
        "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
        "    with torch.no_grad():\n",
        "        inputs = inputs.to(device)\n",
        "        model.eval()\n",
        "        logit = model(inputs).cpu()\n",
        "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
        "    return probs\n",
        "\n",
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "n_classes = 3\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 5000)),\n",
        "                                        ('relu', nn.ReLU()),\n",
        "                                        ('drop', nn.Dropout(p=0.5)),\n",
        "                                        ('fc2', nn.Linear(5000, n_classes)),\n",
        "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "vgg16.classifier = classifier\n",
        "path_vgg16 = 'weigths.pth'\n",
        "vgg16.load_state_dict(torch.load(path_vgg16, map_location='cpu'))\n",
        "\n",
        "''''''\n",
        "#Распознавание основных цветов на изображении\n",
        "\n",
        "def colortable(colors, title):\n",
        "   \n",
        "    width = 212\n",
        "    height = 22\n",
        "    swatch_width = 48\n",
        "    margin = 12\n",
        "    topmargin = 40\n",
        "   \n",
        "    names = list(colors)\n",
        "   \n",
        "    length_of_names = len(names)\n",
        "    length_cols = 1\n",
        "    length_rows = length_of_names\n",
        "   \n",
        "    width2 = width * 2 + 2 * margin\n",
        "    height2 = height * length_rows + margin + topmargin\n",
        "    dpi = 72\n",
        "   \n",
        "    figure, axes = plt.subplots(figsize =(width2 / dpi, height2 / dpi), dpi = dpi)\n",
        "    figure.subplots_adjust(margin / width2, margin / height2,\n",
        "                        (width2-margin)/width2, (height2-topmargin)/height2)\n",
        "      \n",
        "    axes.set_xlim(0, width * 2)\n",
        "    axes.set_ylim(height * (length_rows-0.5), -height / 2.)\n",
        "    axes.set_axis_off()\n",
        "    axes.set_title(title, fontsize = 24, loc =\"left\", pad = 10)\n",
        "   \n",
        "    for i, name in enumerate(names):\n",
        "        rows = i % length_rows\n",
        "        cols = i // length_rows\n",
        "        y = rows * height\n",
        "   \n",
        "        swatch_start_x = width * cols\n",
        "        swatch_end_x = width * cols + swatch_width\n",
        "        text_pos_x = width * cols + swatch_width + 7\n",
        "   \n",
        "        axes.text(text_pos_x, y, name, fontsize = 14,\n",
        "                horizontalalignment ='left',\n",
        "                verticalalignment ='center')\n",
        "   \n",
        "        axes.hlines(y, swatch_start_x, swatch_end_x,\n",
        "                  color = colors[name], linewidth = 18)\n",
        "   \n",
        "    plt.show()\n",
        "    left_column.pyplot(figure)\n",
        "\n",
        "def closest_colour(requested_colour):\n",
        "    min_colours = {}\n",
        "    for key, name in webcolors.CSS3_HEX_TO_NAMES.items():\n",
        "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
        "        rd = (r_c - requested_colour[0]) ** 2\n",
        "        gd = (g_c - requested_colour[1]) ** 2\n",
        "        bd = (b_c - requested_colour[2]) ** 2\n",
        "        min_colours[(rd + gd + bd)] = name\n",
        "    return min_colours[min(min_colours.keys())]\n",
        "\n",
        "def get_colour_name(requested_colour):\n",
        "    try:\n",
        "        closest_name = actual_name = webcolors.rgb_to_name(requested_colour)\n",
        "    except ValueError:\n",
        "        closest_name = closest_colour(requested_colour)\n",
        "        actual_name = None\n",
        "    return closest_name\n",
        "\n",
        "def detect_colors(img):\n",
        "    width, height = img.size\n",
        "\n",
        "    left = width/6\n",
        "    top = height/6\n",
        "    right = width - width/6\n",
        "    bottom = height\n",
        "    img = img.crop((left, top, right, bottom))\n",
        "    img.save('img.jpg')\n",
        "\n",
        "    user_image = ColorDetect('img.jpg')\n",
        "    color_count = user_image.get_color_count(color_format=\"rgb\")\n",
        "\n",
        "    colors = {}\n",
        "    for col in color_count.keys():\n",
        "        rgb_str = col.strip('[]').split(',')\n",
        "        rgb = []\n",
        "        for s in rgb_str:\n",
        "            rgb.append(int(float(s.strip())))\n",
        "        rgb = tuple(rgb)\n",
        "        colors[get_colour_name(rgb)] = tuple(map(lambda x: x/255, rgb))\n",
        "\n",
        "    colortable(colors, \"Основные цвета\")\n",
        "\n",
        "\n",
        "\n",
        "''''''\n",
        "#Основная программа\n",
        "#формирование web-страницы\n",
        "\n",
        "#st.beta_set_page_config(page_title='Kitchens.io', page_icon = ':smiley:', layout = 'centered')\n",
        "st.title(\"Определение параметров кухни\")\n",
        "\n",
        "image = None\n",
        "\n",
        "uploaded_file = st.file_uploader('Выберите или перетащите файл с изображением')\n",
        "if uploaded_file is not None:\n",
        "  image = Image.open(uploaded_file)\n",
        "\n",
        "url = st.text_input('Или введите url-адрес изображения кухни')\n",
        "if url is not '':\n",
        "  jpg = wget.download(url)\n",
        "  image = Image.open(jpg)\n",
        "\n",
        "\n",
        "if image is not None:\n",
        "  placeholder_im = st.empty()\n",
        "  placeholder_time = st.empty()\n",
        "  placeholder_text = st.empty()\n",
        "  left_column, right_column = st.beta_columns(2)\n",
        "  with st.spinner('Пожалуйста, подождите...'):\n",
        "    isKitchen = detect(image.convert('RGB'))\n",
        "  if isKitchen:\n",
        "    kitchen = KitchenDataset([image], mode=\"test\")\n",
        "    prob_pred = predict_one_sample(vgg16, kitchen[0].unsqueeze(0))\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    label_translation = {\n",
        "        'corner_kitchen': 'угловая кухня',\n",
        "        'straight_kitchen': 'прямая кухня',\n",
        "        'island_kitchen': 'островная кухня'\n",
        "    }\n",
        "    with right_column:\n",
        "      st.write('**Конфигурация**: ', label_translation[predicted_label])\n",
        "    detect_colors(image)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing kitchens.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM31N5Bzmgce"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEwbu797oL8D",
        "outputId": "0c140946-7bf8-4e92-f4e3-e09aa770fd38"
      },
      "source": [
        "!ngrok authtoken 1rc4RzY5SsQ5i6k2lEmRCdB6fVu_3KYmFTNN1EBL3ctkAyvL4"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOKhpBoVc331"
      },
      "source": [
        "!streamlit run --server.port 80 kitchens.py&>/dev/null&"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0uQ5DiymkQq"
      },
      "source": [
        "publ_url = ngrok.connect(port='8501')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-uQPCIPo-cg",
        "outputId": "048b67f3-e6ba-406a-d22c-bbaa258d399e"
      },
      "source": [
        "publ_url"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://52e21616b787.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eNNNnvtrVpy"
      },
      "source": [
        "!killall ngrok"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}